<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Introduction to Generative AI</title>
  <style>
    .description {
      font-family: sans-serif;
      font-size: 16px; /* or whatever size you prefer */
      line-height: 1.5;
      text-align: justify;
    }
  </style>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 40px;
      max-width: 1000px;
    }
    h1, h2 {
      color: #2c3e50;
    }
    .button {
      display: inline-block;
      padding: 10px 20px;
      margin: 10px 10px 20px 0;
      background-color: #3498db;
      color: white;
      text-decoration: none;
      border-radius: 5px;
      font-weight: bold;
    }
    .button:hover {
      background-color: #2c80b4;
    }
    ul {
      margin-left: 20px;
      margin-bottom: 30px;
    }
    li {
      margin-bottom: 8px;
    }
  </style>
</head>
<body>

<h1>Generative AI Foundations: Algorithms and Architectures</h1>
<p>
  <a href="https://ajasour.com" target="_blank">Ashkan Jasour</a> | 
  Last modified 2025-04
</p>

<p class="description">
  ‚ÄúGenerative AI Foundations: Algorithms and Architectures‚Äù offers a comprehensive and technical guide to modern generative modeling. It introduces fundamental principles, key algorithms‚Äîsuch as flow models, diffusion models, VAEs, GANs, and autoregressive models‚Äîand the neural architectures‚Äîsuch as CNNs, U-Nets, Transformers, and multimodal frameworks‚Äîthat power state-of-the-art generative AI systems. The course balances mathematical depth with conceptual clarity, presenting precise formulations of modeling goals, corresponding training objectives, and the architectures that realize them.
</p>

<!-- Buttons -->
<a href="assets/slides/CourseSlides.pdf" target="_blank" class="button">üìÑ View Full Course Slides</a>
<a href="https://github.com/jasour/generative-ai-course/tree/main/assets/code" target="_blank" class="button">üíª View Course Codes</a>

<h2>Generative AI - Algorithms</h2>
<ul>
  <li>Flow Models</li>
  <li>Ordinary Differential Equation (ODE)-based Flow Models</li>
  <li>Denoising Diffusion Models (DDMs)</li>
  <li>Stochastic Differential Equation (SDE)-based Denoising Diffusion Models</li>
  <li>Autoencoders and Variational Autoencoders (VAEs)</li>
  <li>Latent Space Diffusion Models</li>
  <li>Autoregressive Models</li>
  <li>Generative Adversarial Networks (GANs)</li>
</ul>

<h2>Generative AI - Architectures</h2>
<ul>
  <li>Multilayer Perceptrons (MLPs)</li>
  <li>Training and Loss Functions Types</li>
  <li>Backpropagation Algorithm</li>
  <li>Stochastic Gradient Descent (SGD) and Adam Optimizer</li>
  <li>Common Training Issues, Regularization in Deep Learning, and Scaling Laws for Deep Learning</li>
  <li>Convolutional Neural Networks (CNNs)</li>
  <li>PixelCNN</li>
  <li>U-Net Denoising Model</li>
  <li>Recurrent Neural Networks (RNNs)</li>
  <li>LSTM (Long Short-Term Memory)</li>
  <li>GRU (Gated Recurrent Unit)</li>
  <li>Transformers: Self-Attention, Multi-Head Attention, and Cross-Attention</li>
  <li>Diffusion Transformers (DiTs)</li>
  <li>Vision Transformers (ViTs)</li>
  <li>Attention-Based U-Nets</li>
  <li>Multimodal Models</li>
  <li>Foundation Models</li>
</ul>

<h2>Appendices</h2>
<ul>
  <li>Key Differential Equations in Generative AI</li>
  <li>Fine-tuning Large Language Models</li>
  <li>Deep Reinforcement Learning - Key Concepts and Summary (PG, VPG, PPO, DDPG, TD3, SAC)</li>
  <li>Reinforcement Learning from Human Feedback (RLHF) and Imitation Learning</li>
  <li>Adversarial Training, Robustness in Language Models, and Language Models Evaluation</li>
  <li>Python Libraries for Generative AI</li>
</ul>

</body>
</html>
